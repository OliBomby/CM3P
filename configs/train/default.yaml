defaults:
  - /train/base@_here_

freeze_beatmap_model: false  # Whether to freeze the beatmap model during training
freeze_metadata_model: false  # Whether to freeze the metadata model during training
attn_implementation: "flash_attention_2"

wandb_project: "CM3P"
wandb_mode: "online"  # Set to "online" to log to wandb server

training:
  use_cpu: false
  bf16: true
  do_train: true
  do_eval: true
  overwrite_output_dir: false
  resume_from_checkpoint: null
  seed: 42
  learning_rate: 1e-4
  per_device_train_batch_size: 8
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 8
  weight_decay: 0.0
  eval_strategy: 'steps'
  eval_steps: 1000
  max_steps: 30000
  logging_strategy: 'steps'
  logging_steps: 10
  save_strategy: 'steps'
  save_steps: 1000
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: 'eval_loss'
  greater_is_better: false
  push_to_hub: false
  dataloader_drop_last: true
  dataloader_num_workers: 4
  torch_empty_cache_steps: 1
  eval_accumulation_steps: 1
  include_for_metrics: ['inputs']
  batch_eval_metrics: true

processor:
  audio_feature_extractor:
    feature_size: 80
    sampling_rate: 16000
    hop_length: 160
    chunk_length: 30
    n_fft: 400
    padding_value: 0
    dither: 0
    return_attention_mask: false

  beatmap_parser:
    add_timing: true
    add_snapping: true
    add_timing_points: true
    add_hitsounds: true
    add_distances: true
    add_positions: true
    add_kiai: true
    add_sv: true
    add_mania_sv: true
    mania_bpm_normalized_scroll_speed: true
    slider_version: 2

  beatmap_tokenizer:
    min_time: 0
    max_time: 16000
    time_step: 10
    max_distance: 640
    distance_step: 4
    position_range: [-256, 768, -256, 640]
    position_step: 4
    position_split_axes: true
    add_cls_token: false
    separate_new_combo_token: true

  metadata_tokenizer:
    min_difficculty: 0.0
    max_difficulty: 14.0
    difficulty_step: 0.1
    min_year: 2000
    max_year: 2023
    max_song_length: 600
    song_length_step: 10
    song_position_step: 0.01
    global_sv_step: 0.01
    hold_note_ratio_step: 0.1
    scroll_speed_ratio_step: 0.1
    add_cls_token: false

  default_kwargs:
      beatmap_kwargs:
        max_length: 4000
        padding: 'longest'
        truncation: 'longest_first'
        window_length_sec: 16.0
        window_stride_sec: 16.0

      metadata_kwargs:
        max_length: 128
        padding: 'longest'
        truncation: 'longest_first'

      audio_kwargs:
        sampling_rate: ${...audio_feature_extractor.sampling_rate}
        padding: false
        truncation: false
        pad_to_multiple_of: 256000
        max_source_positions: 1600
        audio_length_per_tok: 8
        hop_length: ${...audio_feature_extractor.hop_length}
        window_size: ${...audio_feature_extractor.n_fft}

      common_kwargs:
        return_tensors: "pt"

dataset:                  # Data settings
  train_dataset_paths: [ "/workspace/datasets/MMRS39389", "/workspace/datasets/MMUS40000" ]  # Training dataset directory
  train_dataset_start: 0  # Training dataset start index
  train_dataset_end: 78689  # Training dataset end index
  test_dataset_paths: [ "/workspace/datasets/MMRS39389", "/workspace/datasets/MMUS40000" ]  # Testing/validation dataset directory
  test_dataset_start: 78689  # Testing/validation dataset start index
  test_dataset_end: 79389  # Testing/validation dataset end index
  cycle_length: 8  # Number of files to cycle through when loading data to increase batch variety
  drop_last: true  # Drop last incomplete batch
  gamemodes: [ 0, 1, 2, 3 ]  # List of gamemodes to include in the dataset
  min_year: 2000  # Minimum year of the beatmap to include in the dataset
  max_year: 2023  # Maximum year of the beatmap to include in the dataset
  min_difficulty: 0  # Minimum difficulty to consider including in the dataset
  max_difficulty: 14  # Maximum difficulty to consider including in the dataset
  metadata_dropout_prob: 0.2  # Probability of dropping metadata during training
  dt_augment_prob: 0.5  # Probability of augmenting the dataset with DT
  dt_augment_range: [ 1.25, 1.5 ]  # Range of DT augmentation
  dt_augment_sqrt: false  # Sample DT augmentation from a square root distribution
  sampling_rate: ${..processor.audio_feature_extractor.sampling_rate}  # Audio sampling rate
  test_metadata_variations: 1000  # Number of metadata variations to generate during testing
  train_metadata_variations: 1  # Number of metadata variations to generate during training

hydra:
  job:
    chdir: True
  run:
    dir: ./logs/${now:%Y-%m-%d}/${now:%H-%M-%S}